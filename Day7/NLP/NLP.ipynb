{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNcLrZNyQpSF"
   },
   "source": [
    "#Text Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOBMo6c3Xs1K"
   },
   "source": [
    "##Dealing with file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BksyUP3VXyTJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well.\n"
     ]
    }
   ],
   "source": [
    "myfile = open('test.txt')\n",
    "\n",
    "content = myfile.read()\n",
    "\n",
    "print(content)\n",
    "\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cn6nK9iTZqQn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am doing well.']\n"
     ]
    }
   ],
   "source": [
    "myfile = open('test.txt')\n",
    "\n",
    "content = myfile.readlines()\n",
    "\n",
    "print(content)\n",
    "\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_Fwij7GnblPd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well.\n"
     ]
    }
   ],
   "source": [
    "with open('test.txt','r') as txt:\n",
    "    first_line = txt.readlines()[0]\n",
    "\n",
    "print(first_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l9vWWt8VaITT"
   },
   "outputs": [],
   "source": [
    "my_file = open('outtest.txt','w+')\n",
    "\n",
    "my_file.write('This is a new first line')\n",
    "\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mf4RR7hEakIq"
   },
   "outputs": [],
   "source": [
    "# prompt: create a python code to append content in above file\n",
    "\n",
    "my_file = open('outtest.txt','a')\n",
    "\n",
    "my_file.write('\\nThis is a new second line')\n",
    "\n",
    "my_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2n1Cq09avuG"
   },
   "source": [
    "##Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GfHnka3jazKL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "['Hello', 'Hello']\n",
      "Pattern is included\n",
      "[',,,, ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Search for a pattern in a string\n",
    "pattern = \"Hello\"\n",
    "text = \"Hello, world!\"\n",
    "\n",
    "match = re.search(pattern, text)\n",
    "\n",
    "if match:\n",
    "    print(match.group())\n",
    "else:\n",
    "    print(\"Pattern not found\")\n",
    "\n",
    "# Find all occurrences of a pattern in a string\n",
    "pattern = \"Hello\"\n",
    "text = \"Hello, world! Hello, again!\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "print(matches)\n",
    "\n",
    "# Check if a pattern is included in a string\n",
    "pattern = \"Hello\"\n",
    "text = \"Hello, world!\"\n",
    "\n",
    "if re.search(pattern, text):\n",
    "  print(\"Pattern is included\")\n",
    "else:\n",
    "  print(\"Pattern is not included\")\n",
    "\n",
    "# Complex regular expressions\n",
    "pattern = \"(?<=Hello).*(?=world!)\"\n",
    "text = \"222 Hello,,,, world!\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "print(matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn1q6fg0XcWq"
   },
   "source": [
    "# Natural Language Processing With Python's NLTK Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSBl1muAQpSP"
   },
   "source": [
    "### Getting Started With Python’s NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BKwvt-WXQpSU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na0mBMzaQpSX"
   },
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A2XOqgzIQpSY"
   },
   "outputs": [],
   "source": [
    "example_string = \"\"\"Muad'Dib learned rapidly because his first training was in how to learn.\n",
    "And the first lesson of all was the basic trust that he could learn.\n",
    "It's shocking to find how many people do not believe they can learn,\n",
    "and how many more believe learning to be difficult.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vL2qYiUzQpSZ"
   },
   "source": [
    "#### Tokenizing by Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Zm6TekKiQpSZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Muad'Dib learned rapidly because his first training was in how to learn.\", 'And the first lesson of all was the basic trust that he could learn.', \"It's shocking to find how many people do not believe they can learn,\\nand how many more believe learning to be difficult.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences=sent_tokenize(example_string)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LuKFnsr-Tpbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muad'Dib learned rapidly because his first training was in how to learn.\n",
      "And the first lesson of all was the basic trust that he could learn.\n",
      "It's shocking to find how many people do not believe they can learn,\n",
      "and how many more believe learning to be difficult.\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbwZhuD1QpSa"
   },
   "source": [
    "#### Tokenizing by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nQvxg_rfQpSb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Muad'Dib\", 'learned', 'rapidly', 'because', 'his', 'first', 'training', 'was', 'in', 'how', 'to', 'learn', '.', 'And', 'the', 'first', 'lesson', 'of', 'all', 'was', 'the', 'basic', 'trust', 'that', 'he', 'could', 'learn', '.', 'It', \"'s\", 'shocking', 'to', 'find', 'how', 'many', 'people', 'do', 'not', 'believe', 'they', 'can', 'learn', ',', 'and', 'how', 'many', 'more', 'believe', 'learning', 'to', 'be', 'difficult', '.']\n",
      "Muad'Dib\n",
      "learned\n",
      "rapidly\n",
      "because\n",
      "his\n",
      "first\n",
      "training\n",
      "was\n",
      "in\n",
      "how\n",
      "to\n",
      "learn\n",
      ".\n",
      "And\n",
      "the\n",
      "first\n",
      "lesson\n",
      "of\n",
      "all\n",
      "was\n",
      "the\n",
      "basic\n",
      "trust\n",
      "that\n",
      "he\n",
      "could\n",
      "learn\n",
      ".\n",
      "It\n",
      "'s\n",
      "shocking\n",
      "to\n",
      "find\n",
      "how\n",
      "many\n",
      "people\n",
      "do\n",
      "not\n",
      "believe\n",
      "they\n",
      "can\n",
      "learn\n",
      ",\n",
      "and\n",
      "how\n",
      "many\n",
      "more\n",
      "believe\n",
      "learning\n",
      "to\n",
      "be\n",
      "difficult\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words=word_tokenize(example_string)\n",
    "print(words)\n",
    "for w in words:\n",
    "  print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "18Vg8Ed7U9Hx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Muad'Dib learned rapidly because his first training was in how to learn.\", 'And the first lesson of all was the basic trust that he could learn.', \"It's shocking to find how many people do not believe they can learn,\\nand how many more believe learning to be difficult.\"]\n",
      "[[\"Muad'Dib\", 'learned', 'rapidly', 'because', 'his', 'first', 'training', 'was', 'in', 'how', 'to', 'learn', '.'], ['And', 'the', 'first', 'lesson', 'of', 'all', 'was', 'the', 'basic', 'trust', 'that', 'he', 'could', 'learn', '.'], ['It', \"'s\", 'shocking', 'to', 'find', 'how', 'many', 'people', 'do', 'not', 'believe', 'they', 'can', 'learn', ',', 'and', 'how', 'many', 'more', 'believe', 'learning', 'to', 'be', 'difficult', '.']]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "print(sentences)\n",
    "for s in sentences:\n",
    "  data.append(word_tokenize(s))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwW_RSj2QpSb"
   },
   "source": [
    "### Filtering Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-GCBoviQpSc"
   },
   "source": [
    "Stop words are words that you want to ignore, so you filter them out of your text when you’re processing it. Very common words like 'in', 'is', and 'an' are often used as stop words since they don’t add a lot of meaning to a text in and of themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BKMglYMMQpSc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "V6MnI5GrQpSd"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "D2Oi0Ka_XBXb"
   },
   "outputs": [],
   "source": [
    "#special character removal\n",
    "#['Sir', 'protest', 'merry', 'man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Bz_VSLEqQpSd"
   },
   "outputs": [],
   "source": [
    "worf_quote = \"Sir, I protest. I am not a merry man!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Vh6FiBRUQpSe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sir', ',', 'I', 'protest', '.', 'I', 'am', 'not', 'a', 'merry', 'man', '!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_quote = word_tokenize(worf_quote)\n",
    "print(words_in_quote)\n",
    "len(words_in_quote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FKyVNbQcQpSe"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xsCNNjvDQpSf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OXgCUwtPYcwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kc-FM-e8QpSf"
   },
   "outputs": [],
   "source": [
    "filtered_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "VOeXA4UPuXbm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sir', ',', 'I', 'protest', '.', 'I', 'am', 'not', 'a', 'merry', 'man', '!']\n"
     ]
    }
   ],
   "source": [
    "print(words_in_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "m_34RKJ9QpSf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sir', ',', 'protest', '.', 'merry', 'man', '!']\n"
     ]
    }
   ],
   "source": [
    "for word in words_in_quote:\n",
    "    if word.casefold() not in stop_words:\n",
    "        filtered_list.append(word)\n",
    "\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "K53jWjlLQpSg"
   },
   "outputs": [],
   "source": [
    "filtered_list = [\n",
    "    word for word in words_in_quote if word.casefold() not in stop_words\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zZ-ZUAe3QpSg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sir', ',', 'protest', '.', 'merry', 'man', '!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN25q9B0QpSg"
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU6HZZbcYAIW"
   },
   "source": [
    "When we have many variations of a same word.eg: the root word is dance and variations are dancing, dance, danced. Stemming algorithm works by cutting the suffix from the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ljE8OFaOQpSh"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# PorterStemmer is an algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ohtd-mFrQpSh"
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()  #steamer is an abject of porterstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4H6T6X0hQpSh"
   },
   "outputs": [],
   "source": [
    "# string_for_stemming = \"\"\"\n",
    "# The crew of the USS Discovery discovered many discoveries.\n",
    "# Discovering is what explorers do.\"\"\"\n",
    "string_for_stemming =\"The friends of DeSoto love scarves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "GTB62OkcQpSi"
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(string_for_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tVosWBQZQpSi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'friends', 'of', 'DeSoto', 'love', 'scarves']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Sen6ITABQpSi"
   },
   "outputs": [],
   "source": [
    "stemmed_words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "lR40S23oQpSj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'friend', 'of', 'desoto', 'love', 'scarv']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_inioMpVQpSm"
   },
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwLMUPsAdB_6"
   },
   "source": [
    "It switches any kind of a word to its base root form(lemma). Lemmatization is responsible for grouping different inflected forms of words into the root form, having the same meaning.\n",
    "\n",
    "**Why Lemmatizing is better than stemming?**\n",
    "\n",
    "Stem may not be an actual word whereas, lemma is an actual language word.\n",
    "Stemming follows an algorithm with steps to perform on the words which makes it faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "a5UPIZGWQpSm"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Jmh-QcmAQpSm"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "2QXYleo7QpSm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qbqMxvQHQpSm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'scarf'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "lemmatizer.lemmatize(\"scarves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-owJR78gQpSn"
   },
   "outputs": [],
   "source": [
    "string_for_lemmatizing = \"The friends of DeSoto love scarves.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "hQTZcClWQpSn"
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(string_for_lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BR_cH2HOQpSn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'friends', 'of', 'DeSoto', 'love', 'scarves', '.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "OhjFFCHXQpSn"
   },
   "outputs": [],
   "source": [
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "JleqXUy3QpSo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'friend', 'of', 'DeSoto', 'love', 'scarf', '.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "cMhslkCLQpSo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "fN5BiVb3QpSo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/90/f0/0133b684e18932c7bf4075d94819746cee2c0329f2569db526b0fa1df1df/spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/71/46/af01a20ec368bd9cb49a1d2df15e3eca113bbf6952cc1f2a47f1c6801a7f/murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/c1/c3/dd044e6f62a3d317c461f6f0c153c6573ed13025752d779e514000c15dd2/cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.1.8 from https://files.pythonhosted.org/packages/74/24/564a7df5b1fac0520f6b55137deea2cc0b6f7d6e66228f1645dbfd59bb33/thinc-8.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.2.2-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/eb/f5/e3f29993f673d91623df6413ba64e815dd2676fd7932cbc5e7347402ddae/srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.4.0,>=0.1.0 from https://files.pythonhosted.org/packages/d5/e5/b63b8e255d89ba4155972990d42523251d4d1368c4906c646597f63870e2/weasel-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.9/45.9 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/e4/37/3ffe6e7daa1ea1b4bf5228807a92ccbae538cf57c0c50b93564c310c11a8/pydantic-2.6.0-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.6.0-py3-none-any.whl.metadata (81 kB)\n",
      "     ---------------------------------------- 0.0/81.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 81.8/81.8 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy) (23.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Obtaining dependency information for pydantic-core==2.16.1 from https://files.pythonhosted.org/packages/b2/47/14bf2397a5daa0cc1b99306499a39525966b73aba4d31b17e373e229f07e/pydantic_core-2.16.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.16.1-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/2f/09/da0592c74560cc33396504698122f7a56747c82a5e072ca7d2c3397898e1/blis-0.7.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/39/78/f9d18da7b979a2e6007bfcea2f3c8cc02ed210538ae1ce7e69092aed7b18/confection-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shail\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<0.17.0,>=0.7.0 from https://files.pythonhosted.org/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/12.1 MB 3.4 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.6/12.1 MB 3.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/12.1 MB 3.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/12.1 MB 3.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/12.1 MB 3.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.2/12.1 MB 3.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.4/12.1 MB 3.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.5/12.1 MB 2.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.7/12.1 MB 2.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.9/12.1 MB 2.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.5/12.1 MB 3.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.2/12.1 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.2/12.1 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.2/12.1 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/12.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.8/12.1 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.9/12.1 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.0/12.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.1/12.1 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.2/12.1 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.4/12.1 MB 3.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.5/12.1 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.8/12.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.9/12.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.1/12.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.5/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.6/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/12.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.9/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.1/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.2/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/12.1 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.4/12.1 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.4/12.1 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.5/12.1 MB 3.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.6/12.1 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.6/12.1 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.7/12.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.9/12.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.0/12.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.3/12.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.3/12.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.4/12.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.5/12.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/12.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.7/12.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.8/12.1 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.9/12.1 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.1 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.2/12.1 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.1 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.5/12.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.5/12.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.6/12.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.8/12.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.0/12.1 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.1/12.1 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.2/12.1 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.2/12.1 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.3/12.1 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.4/12.1 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.5/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.8/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.9/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.4/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.9/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.2/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.4/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 112.6/122.3 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 122.3/122.3 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.0-py3-none-any.whl (394 kB)\n",
      "   ---------------------------------------- 0.0/394.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 143.4/394.2 kB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 235.5/394.2 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 337.9/394.2 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 394.2/394.2 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.1-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 8.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/1.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/1.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/1.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.4/1.9 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/1.9 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 276.5/479.7 kB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 409.6/479.7 kB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 479.7/479.7 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.2-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.5 MB 3.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.2/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/6.6 MB 4.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.2/6.6 MB 2.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.5/6.6 MB 3.7 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.5/6.6 MB 3.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/6.6 MB 2.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.7/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.8/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.9/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.1/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.2/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.3/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.4/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.4/6.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.4/6.6 MB 2.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.5/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.9/6.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.2/6.6 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.5/6.6 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/6.6 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/6.6 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/6.6 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.0/6.6 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.6/6.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.9/6.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.2/6.6 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.8/6.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.0/6.6 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.4/6.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.8/6.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.3/6.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, pydantic-core, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.6.0 pydantic-core-2.16.1 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.2 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------------------- 0.0/12.8 MB 393.8 kB/s eta 0:00:33\n",
      "     --------------------------------------- 0.1/12.8 MB 573.4 kB/s eta 0:00:23\n",
      "     --------------------------------------- 0.2/12.8 MB 838.4 kB/s eta 0:00:16\n",
      "      -------------------------------------- 0.2/12.8 MB 986.4 kB/s eta 0:00:13\n",
      "      --------------------------------------- 0.3/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.7/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.9/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.5 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.0/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 2.2/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 2.7/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 2.8/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 2.9/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 3.0/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 3.1/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 4.0/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 4.1/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.2/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.3/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.4/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.5/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 4.5/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 4.6/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 4.8/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 4.9/12.8 MB 2.0 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.0/12.8 MB 2.0 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.1/12.8 MB 2.0 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 5.9/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 6.0/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.1/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.4/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.7/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.9/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.0/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 7.8/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.1/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.3/12.8 MB 2.4 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 2.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 2.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.8/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.9/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.0/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.1/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.3/12.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shail\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LBDmtWRfMD-"
   },
   "source": [
    "##Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "aIpGzbqLfQpM"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "oppuyihkf6rI"
   },
   "outputs": [],
   "source": [
    "#vocabulary matching\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "\n",
    "matcher.add('SolarPower',[pattern1,pattern2,pattern3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "C-RJgnq1g6Gh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJUvCLRAh6_C"
   },
   "source": [
    "## Part of Speech Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "PppzLgx7hAiN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT', 'DET'), ('quick', 'JJ', 'ADJ'), ('brown', 'JJ', 'ADJ'), ('fox', 'NN', 'NOUN'), ('jumped', 'VBD', 'VERB'), ('over', 'IN', 'ADP'), ('the', 'DT', 'DET'), ('lazy', 'JJ', 'ADJ'), ('dog', 'NN', 'NOUN'), ('.', '.', 'PUNCT')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0c02a0009078459e80a9775ed8e7e94e-0\" class=\"displacy\" width=\"860\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">dog.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,2.0 320.0,2.0 320.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,47.0 315.0,47.0 315.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-4\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490.0,139.0 L498.0,127.0 482.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,47.0 765.0,47.0 765.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-6\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,139.0 L692,127.0 708,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0c02a0009078459e80a9775ed8e7e94e-0-7\" stroke-width=\"2px\" d=\"M520,137.0 C520,2.0 770.0,2.0 770.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0c02a0009078459e80a9775ed8e7e94e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,139.0 L778.0,127.0 762.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prompt: generate code for demonstrating pos tagginh options in spacy and visualizing it\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Get the text\n",
    "text = \"The quick brown fox jumped over the lazy dog.\"\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(text)\n",
    "\n",
    "# Get the part-of-speech tags\n",
    "tags = [(token.text,token.tag_,token.pos_) for token in doc]\n",
    "\n",
    "# Print the tags\n",
    "print(tags)\n",
    "\n",
    "# Visualize the part-of-speech tags\n",
    "displacy.render(doc, style='dep',jupyter=True, options={'distance': 90})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adposition'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy import glossary\n",
    "tag_name = 'ADP'\n",
    "glossary.explain(tag_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adAaQHiVjryp"
   },
   "source": [
    "##Named Entity Recogntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ggiDJKJDkBp7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mohandas Karamchand Gandhi PERSON\n",
      "Indian NORP\n",
      "India GPE\n",
      "British NORP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mohandas Karamchand Gandhi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was an \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " lawyer, anti-colonial nationalist and political ethicist who employed nonviolent resistance to lead the successful campaign for \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s independence from \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    British\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " rule. He inspired movements for civil rights and freedom across the world.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prompt: demo the code for NER in detail and its visualization   on a large paragraph\n",
    "\n",
    "text = \"Mohandas Karamchand Gandhi was an Indian lawyer, anti-colonial nationalist and political ethicist who employed nonviolent resistance to lead the successful campaign for India's independence from British rule. He inspired movements for civil rights and freedom across the world.\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_I9xOilfQpSp"
   },
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Textblob in c:\\users\\shail\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from Textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk>=3.1->Textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk>=3.1->Textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk>=3.1->Textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shail\\anaconda3\\lib\\site-packages (from nltk>=3.1->Textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shail\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->Textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install Textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvTZVbPhQpSp"
   },
   "source": [
    "N-grams are the combination of multiple words used together. Ngrams with N=1 are called unigrams. Similarly, bigrams (N=2), trigrams (N=3) and so on can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ETsVty1AQpSp"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "C48eNyfkQpSp"
   },
   "outputs": [],
   "source": [
    "example_string = \"\"\"Muad'Dib learned rapidly because his first training was in how to learn.\n",
    "And the first lesson of all was the basic trust that he could learn.\n",
    "It's shocking to find how many people do not believe they can learn,\n",
    "and how many more believe learning to be difficult.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "10S9QNBoQpSq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList([\"Muad'Dib\", 'learned', 'rapidly']),\n",
       " WordList(['learned', 'rapidly', 'because']),\n",
       " WordList(['rapidly', 'because', 'his']),\n",
       " WordList(['because', 'his', 'first']),\n",
       " WordList(['his', 'first', 'training']),\n",
       " WordList(['first', 'training', 'was']),\n",
       " WordList(['training', 'was', 'in']),\n",
       " WordList(['was', 'in', 'how']),\n",
       " WordList(['in', 'how', 'to']),\n",
       " WordList(['how', 'to', 'learn']),\n",
       " WordList(['to', 'learn', 'And']),\n",
       " WordList(['learn', 'And', 'the']),\n",
       " WordList(['And', 'the', 'first']),\n",
       " WordList(['the', 'first', 'lesson']),\n",
       " WordList(['first', 'lesson', 'of']),\n",
       " WordList(['lesson', 'of', 'all']),\n",
       " WordList(['of', 'all', 'was']),\n",
       " WordList(['all', 'was', 'the']),\n",
       " WordList(['was', 'the', 'basic']),\n",
       " WordList(['the', 'basic', 'trust']),\n",
       " WordList(['basic', 'trust', 'that']),\n",
       " WordList(['trust', 'that', 'he']),\n",
       " WordList(['that', 'he', 'could']),\n",
       " WordList(['he', 'could', 'learn']),\n",
       " WordList(['could', 'learn', 'It']),\n",
       " WordList(['learn', 'It', \"'s\"]),\n",
       " WordList(['It', \"'s\", 'shocking']),\n",
       " WordList([\"'s\", 'shocking', 'to']),\n",
       " WordList(['shocking', 'to', 'find']),\n",
       " WordList(['to', 'find', 'how']),\n",
       " WordList(['find', 'how', 'many']),\n",
       " WordList(['how', 'many', 'people']),\n",
       " WordList(['many', 'people', 'do']),\n",
       " WordList(['people', 'do', 'not']),\n",
       " WordList(['do', 'not', 'believe']),\n",
       " WordList(['not', 'believe', 'they']),\n",
       " WordList(['believe', 'they', 'can']),\n",
       " WordList(['they', 'can', 'learn']),\n",
       " WordList(['can', 'learn', 'and']),\n",
       " WordList(['learn', 'and', 'how']),\n",
       " WordList(['and', 'how', 'many']),\n",
       " WordList(['how', 'many', 'more']),\n",
       " WordList(['many', 'more', 'believe']),\n",
       " WordList(['more', 'believe', 'learning']),\n",
       " WordList(['believe', 'learning', 'to']),\n",
       " WordList(['learning', 'to', 'be']),\n",
       " WordList(['to', 'be', 'difficult'])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(example_string).ngrams(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQA_ZhjoQpSo"
   },
   "source": [
    "# Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blkoSPXTQpSq"
   },
   "source": [
    "## Bag of Words(BOW) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDb6csiGQpSq"
   },
   "source": [
    "Bag of Words (BoW) refers to the representation of text which describes the presence of words within the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "6pB227f0QpSq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "uV_0SPUuQpSq"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "DjUpwR6PQpSr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   computers  future  in  is  learn  love  months  nlp  they  two  will\n",
      "0          1       0   0   0      0     2       0    1     2    0     0\n",
      "1          0       1   0   1      0     0       0    1     0    0     0\n",
      "2          0       0   1   0      1     0       1    0     1    1     1\n"
     ]
    }
   ],
   "source": [
    "text = [\"They love NLP, they love computers\",\n",
    "        \"NLP is future\",\n",
    "        \"They will learn in two months\"]\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(text)\n",
    "count_array = count_matrix.toarray()\n",
    "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "wM4eOQLTQpSr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   computers  future  in  is  learn  love  months  nlp  they  two  will\n",
      "0          0       0   1   0      1     1       1    1     1    1     0\n"
     ]
    }
   ],
   "source": [
    "text2 = ['They love NLP but can not learn in two months']\n",
    "count_array=vectorizer.transform(text2).toarray()\n",
    "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "IzTuUb6xQpSr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   am not  feeling bad  food was  not bad  not feeling  was not\n",
      "0       0            0         1        1            0        1\n",
      "1       1            1         0        0            1        0\n"
     ]
    }
   ],
   "source": [
    "text = [\"food was not bad\",\"I am not feeling bad\"]\n",
    "vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "count_matrix = vectorizer.fit_transform(text)\n",
    "count_array = count_matrix.toarray()\n",
    "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHXSiSx3QpSs"
   },
   "source": [
    "## Term Frequency – Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "wr4zM6rdQpSs"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "TfTqqA6OQpSs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     future        is     learn      love       nlp       the      will\n",
      "0  0.000000  0.000000  0.000000  0.767495  0.453295  0.453295  0.000000\n",
      "1  0.608845  0.608845  0.000000  0.000000  0.359594  0.359594  0.000000\n",
      "2  0.000000  0.000000  0.608845  0.000000  0.359594  0.359594  0.608845\n"
     ]
    }
   ],
   "source": [
    "text = [\"i love the NLP\",\n",
    "        \"NLP is the future\",\n",
    "        \"i will learn the NLP\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(text)\n",
    "count_array = matrix.toarray()\n",
    "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37G0UK4cQpSt"
   },
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm29MEd7QpSt"
   },
   "source": [
    "Word Embedding is the representation of text in the form of vectors. The underlying idea here is that similar words will have a minimum distance between their vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "MMJq6doINaNW"
   },
   "outputs": [],
   "source": [
    "X=[d.split() for d in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "qZujy5UZOPXf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'love', 'the', 'NLP'],\n",
       " ['NLP', 'is', 'the', 'future'],\n",
       " ['i', 'will', 'learn', 'the', 'NLP']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "USZBhD3IQpSt"
   },
   "outputs": [],
   "source": [
    "#convert text into the word2vec format.\n",
    "import gensim\n",
    "w2vecmodel=gensim.models.Word2Vec(sentences=X,vector_size=2,window=4,min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj7X5ZV3QpSu"
   },
   "source": [
    "Now, we can load the above word2vec file as a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "OuHBpap_QpSu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=8, vector_size=2, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(w2vecmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "2pbKY0v6QpSu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'the', 'i', 'learn', 'will', 'future', 'is', 'love']\n"
     ]
    }
   ],
   "source": [
    "words = w2vecmodel.wv.index_to_key\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "MXBa49-rJM3h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NLP', 'the', 'i', 'learn', 'will', 'future', 'is', 'love'])\n"
     ]
    }
   ],
   "source": [
    "words = w2vecmodel.wv.key_to_index\n",
    "print(words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "GXm4bkVQQpSu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "print(words.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "pknB4PAUQpSv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02681136  0.01182157]\n",
      " [ 0.25516748  0.45046365]\n",
      " [-0.4651475  -0.35584044]\n",
      " [ 0.32294363  0.4486494 ]\n",
      " [-0.2507714  -0.18816859]\n",
      " [ 0.36902523 -0.07667357]\n",
      " [-0.22683066  0.32770258]\n",
      " [-0.24300802 -0.09080088]]\n"
     ]
    }
   ],
   "source": [
    "print(w2vecmodel.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ZH8Pb2TkP_Pw"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y = w2vecmodel.wv.vectors[:,0]\n",
    "x = w2vecmodel.wv.vectors[:,1]\n",
    "labels = words.keys()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (x[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
