{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yKuPknjpplP"
   },
   "source": [
    "Demo for Text Classification for sentiment analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1706336609798,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "SxrIWAwtJSvD",
    "outputId": "f793dfa3-5447-4c90-9e99-c926b704db3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rock destined st century new conan going make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gorgeously elaborate continuation lord ring tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sometimes like go movie fun wasabi good place ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges something rare issue movie honest keen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>film provides great insight neurotic mindset c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>offer rare combination entertainment education</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>perhaps picture ever made literally showed roa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>steer turn snappy screenplay curl edge clever ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>take care cat offer refreshingly different sli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary  Sentiment\n",
       "0  rock destined st century new conan going make ...          1\n",
       "1  gorgeously elaborate continuation lord ring tr...          1\n",
       "2                             effective tepid biopic          1\n",
       "3  sometimes like go movie fun wasabi good place ...          1\n",
       "4  emerges something rare issue movie honest keen...          1\n",
       "5  film provides great insight neurotic mindset c...          1\n",
       "6     offer rare combination entertainment education          1\n",
       "7  perhaps picture ever made literally showed roa...          1\n",
       "8  steer turn snappy screenplay curl edge clever ...          1\n",
       "9  take care cat offer refreshingly different sli...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#placing the reviews labelled as 1 or 0 into a dataframe.\n",
    "\n",
    "import pandas as pd\n",
    "df= pd.read_csv('movie_reviews.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1706336661345,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "Nq8ZAwgWJ7C6"
   },
   "outputs": [],
   "source": [
    "summary = df.Summary.values\n",
    "labels = df.Sentiment.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1706336663791,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "Y19C5sR4KJhG",
    "outputId": "11c589c4-869b-4dd7-a58d-fcbbd3451a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nelson screenplay need serious working show dilemma rather character stage shouting match   0\n"
     ]
    }
   ],
   "source": [
    "print(summary[10655],\" \",labels[10655])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706335259393,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "gEWC1mWi7Bpp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(summary,labels,test_size=0.2,random_state=123,stratify=labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2767,
     "status": "ok",
     "timestamp": 1706335262156,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "nesuPgoCGRFI",
    "outputId": "78d53fbd-e042-4da6-cdd0-a0362488bd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529, 14775)\n",
      "(2133, 14775)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data to obtain TF-IDF representations\n",
    "tfidf_matrix = vectorizer.fit_transform(X_train).toarray()\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "# Print the vocabulary (mapping of terms to feature indices)\n",
    "#print(vectorizer.vocabulary_)\n",
    "\n",
    "# Transform the test data using the same vectorizer\n",
    "tfidf_test_vectors = vectorizer.transform(X_test).toarray()\n",
    "print(tfidf_test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174948,
     "status": "ok",
     "timestamp": 1706337192405,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "Sz_q20Jz7-k-",
    "outputId": "79856c96-d297-4b0b-9af5-8bf024871208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72      1067\n",
      "           1       0.73      0.64      0.68      1066\n",
      "\n",
      "    accuracy                           0.70      2133\n",
      "   macro avg       0.70      0.70      0.70      2133\n",
      "weighted avg       0.70      0.70      0.70      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(tfidf_matrix,y_train)\n",
    "y_pred = classifier.predict(tfidf_test_vectors)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1706335437016,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "26Ckq4Op9mXH"
   },
   "outputs": [],
   "source": [
    "# TF-IDF vectorization using scikit-learn\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706335437016,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "MOcnl9PH7VE0",
    "outputId": "aa4bef4b-6f64-41f6-accf-8036db7b25fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529, 14775)\n",
      "No: of the reviews 8529\n",
      "No: of the terms 14775\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape)\n",
    "\n",
    "print(\"No: of the reviews\",X_train_tfidf.shape[0])\n",
    "print(\"No: of the terms\",X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343328,
     "status": "ok",
     "timestamp": 1706335780343,
     "user": {
      "displayName": "Shilpa Shaju",
      "userId": "05321445223055868226"
     },
     "user_tz": -330
    },
    "id": "4MAi6i4v_3We",
    "outputId": "5c456f08-3e20-4303-e374-1ff076e9cfc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4265/4265 [==============================] - 74s 17ms/step - loss: 0.5613 - accuracy: 0.7032 - val_loss: 0.4901 - val_accuracy: 0.7567\n",
      "Epoch 2/5\n",
      "4265/4265 [==============================] - 67s 16ms/step - loss: 0.2403 - accuracy: 0.9013 - val_loss: 0.5956 - val_accuracy: 0.7557\n",
      "Epoch 3/5\n",
      "4265/4265 [==============================] - 67s 16ms/step - loss: 0.0847 - accuracy: 0.9666 - val_loss: 1.0100 - val_accuracy: 0.7496\n",
      "Epoch 4/5\n",
      "4265/4265 [==============================] - 64s 15ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 1.6319 - val_accuracy: 0.7478\n",
      "Epoch 5/5\n",
      "4265/4265 [==============================] - 68s 16ms/step - loss: 0.0084 - accuracy: 0.9965 - val_loss: 2.5337 - val_accuracy: 0.7445\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 2.5337 - accuracy: 0.7445\n",
      "Test Loss: 2.5336568355560303, Test Accuracy: 0.7444913387298584\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Build a neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_tfidf.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train, epochs=5, batch_size=2, validation_data=(X_test_tfidf, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "198OxymMRfeBhFrI_jUHfJADNaPhPPgH4",
     "timestamp": 1706287316561
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
