{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suadamohammed/NLP/blob/main/Text_Feature_Extraction_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNcLrZNyQpSF"
      },
      "source": [
        "# Natural Language Processing With Python's NLTK Package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSBl1muAQpSP"
      },
      "source": [
        "### Getting Started With Python’s NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BKwvt-WXQpSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f7c282-1f7a-45aa-e822-6c8eaf746681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na0mBMzaQpSX"
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A2XOqgzIQpSY"
      },
      "outputs": [],
      "source": [
        "example_string = \"\"\"Muad'Dib learned rapidly because his first training was in how to learn.\n",
        "And the first lesson of all was the basic trust that he could learn.\n",
        "It's shocking to find how many people do not believe they can learn,\n",
        "and how many more believe learning to be difficult.\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2qYiUzQpSZ"
      },
      "source": [
        "#### Tokenizing by Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zm6TekKiQpSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab60f4a-c9b7-49fe-910c-63e2229cee61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Muad'Dib learned rapidly because his first training was in how to learn.\", 'And the first lesson of all was the basic trust that he could learn.', \"It's shocking to find how many people do not believe they can learn,\\nand how many more believe learning to be difficult.\"]\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize  \n",
        "\n",
        "sentences=sent_tokenize(example_string)\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in sentences:\n",
        "  print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuKFnsr-Tpbd",
        "outputId": "64f27981-95c8-43f0-d62f-b4e9209efbd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muad'Dib learned rapidly because his first training was in how to learn.\n",
            "And the first lesson of all was the basic trust that he could learn.\n",
            "It's shocking to find how many people do not believe they can learn,\n",
            "and how many more believe learning to be difficult.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbwZhuD1QpSa"
      },
      "source": [
        "#### Tokenizing by word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQvxg_rfQpSb",
        "outputId": "e3fcf7d9-a371-4950-e237-faca2c82299c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Muad'Dib\", 'learned', 'rapidly', 'because', 'his', 'first', 'training', 'was', 'in', 'how', 'to', 'learn', '.', 'And', 'the', 'first', 'lesson', 'of', 'all', 'was', 'the', 'basic', 'trust', 'that', 'he', 'could', 'learn', '.', 'It', \"'s\", 'shocking', 'to', 'find', 'how', 'many', 'people', 'do', 'not', 'believe', 'they', 'can', 'learn', ',', 'and', 'how', 'many', 'more', 'believe', 'learning', 'to', 'be', 'difficult', '.']\n",
            "Muad'Dib\n",
            "learned\n",
            "rapidly\n",
            "because\n",
            "his\n",
            "first\n",
            "training\n",
            "was\n",
            "in\n",
            "how\n",
            "to\n",
            "learn\n",
            ".\n",
            "And\n",
            "the\n",
            "first\n",
            "lesson\n",
            "of\n",
            "all\n",
            "was\n",
            "the\n",
            "basic\n",
            "trust\n",
            "that\n",
            "he\n",
            "could\n",
            "learn\n",
            ".\n",
            "It\n",
            "'s\n",
            "shocking\n",
            "to\n",
            "find\n",
            "how\n",
            "many\n",
            "people\n",
            "do\n",
            "not\n",
            "believe\n",
            "they\n",
            "can\n",
            "learn\n",
            ",\n",
            "and\n",
            "how\n",
            "many\n",
            "more\n",
            "believe\n",
            "learning\n",
            "to\n",
            "be\n",
            "difficult\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize  \n",
        "\n",
        "words=word_tokenize(example_string)\n",
        "print(words)\n",
        "for w in words:\n",
        "  print(w)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "print(sentences)\n",
        "for s in sentences:\n",
        "  data.append(word_tokenize(s))\n",
        "print(data) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Vg8Ed7U9Hx",
        "outputId": "d4e204f3-0384-49cc-bf6b-887d4876acca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Muad'Dib learned rapidly because his first training was in how to learn.\", 'And the first lesson of all was the basic trust that he could learn.', \"It's shocking to find how many people do not believe they can learn,\\nand how many more believe learning to be difficult.\"]\n",
            "[[\"Muad'Dib\", 'learned', 'rapidly', 'because', 'his', 'first', 'training', 'was', 'in', 'how', 'to', 'learn', '.'], ['And', 'the', 'first', 'lesson', 'of', 'all', 'was', 'the', 'basic', 'trust', 'that', 'he', 'could', 'learn', '.'], ['It', \"'s\", 'shocking', 'to', 'find', 'how', 'many', 'people', 'do', 'not', 'believe', 'they', 'can', 'learn', ',', 'and', 'how', 'many', 'more', 'believe', 'learning', 'to', 'be', 'difficult', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwW_RSj2QpSb"
      },
      "source": [
        "### Filtering Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-GCBoviQpSc"
      },
      "source": [
        "Stop words are words that you want to ignore, so you filter them out of your text when you’re processing it. Very common words like 'in', 'is', and 'an' are often used as stop words since they don’t add a lot of meaning to a text in and of themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKMglYMMQpSc",
        "outputId": "52114746-373e-47d1-f1a8-bd9e36af082b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V6MnI5GrQpSd"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#special character removal\n",
        "#['Sir', 'protest', 'merry', 'man']"
      ],
      "metadata": {
        "id": "D2Oi0Ka_XBXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bz_VSLEqQpSd"
      },
      "outputs": [],
      "source": [
        "worf_quote = \"Sir, I protest. I am not a merry man!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh6FiBRUQpSe",
        "outputId": "23626178-9e7e-4c2b-ad82-458a0a5e3ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sir', ',', 'I', 'protest', '.', 'I', 'am', 'not', 'a', 'merry', 'man', '!']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "words_in_quote = word_tokenize(worf_quote)\n",
        "print(words_in_quote)\n",
        "len(words_in_quote)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FKyVNbQcQpSe"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xsCNNjvDQpSf",
        "outputId": "95f20519-22c8-48a0-9d1a-c2171e4e8069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "stop_words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXgCUwtPYcwL",
        "outputId": "60d5d20a-3b7f-4c33-ae31-5134b5d45b66"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kc-FM-e8QpSf"
      },
      "outputs": [],
      "source": [
        "filtered_list = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_in_quote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOeXA4UPuXbm",
        "outputId": "00e5f8b3-54b2-439e-e30f-9f270c878501"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sir', ',', 'I', 'protest', '.', 'I', 'am', 'not', 'a', 'merry', 'man', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m_34RKJ9QpSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1047ac49-9c45-49f0-b02b-9106168404d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sir', ',', 'protest', '.', 'merry', 'man', '!']\n"
          ]
        }
      ],
      "source": [
        "for word in words_in_quote:\n",
        "    if word.casefold() not in stop_words:\n",
        "        filtered_list.append(word)\n",
        "        \n",
        "print(filtered_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "K53jWjlLQpSg"
      },
      "outputs": [],
      "source": [
        "filtered_list = [\n",
        "    word for word in words_in_quote if word.casefold() not in stop_words\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ-ZUAe3QpSg",
        "outputId": "8211ec18-ede5-4843-d5dd-ee54524fe18f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sir', ',', 'protest', '.', 'merry', 'man', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "filtered_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN25q9B0QpSg"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we have many variations of a same word.eg: the root word is dance and variations are dancing, dance, danced. Stemming algorithm works by cutting the suffix from the word."
      ],
      "metadata": {
        "id": "PU6HZZbcYAIW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ljE8OFaOQpSh"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "# PorterStemmer is an algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ohtd-mFrQpSh"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()  #steamer is an abject of porterstemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4H6T6X0hQpSh"
      },
      "outputs": [],
      "source": [
        "# string_for_stemming = \"\"\"\n",
        "# The crew of the USS Discovery discovered many discoveries.\n",
        "# Discovering is what explorers do.\"\"\"\n",
        "string_for_stemming =\"The friends of DeSoto love scarves\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GTB62OkcQpSi"
      },
      "outputs": [],
      "source": [
        "words = word_tokenize(string_for_stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tVosWBQZQpSi",
        "outputId": "b25b56ae-ef4d-4520-e382-460b43082036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'friends', 'of', 'DeSoto', 'love', 'scarves']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Sen6ITABQpSi"
      },
      "outputs": [],
      "source": [
        "stemmed_words = [stemmer.stem(word) for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR40S23oQpSj",
        "outputId": "6a332624-5115-4213-e43e-53844e4c5a5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'friend', 'of', 'desoto', 'love', 'scarv']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "stemmed_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_inioMpVQpSm"
      },
      "source": [
        "## Lemmatizing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It switches any kind of a word to its base root form(lemma). Lemmatization is responsible for grouping different inflected forms of words into the root form, having the same meaning.\n",
        "\n",
        "**Why Lemmatizing is better than stemming?**\n",
        "\n",
        "Stem may not be an actual word whereas, lemma is an actual language word.\n",
        "Stemming follows an algorithm with steps to perform on the words which makes it faster.\n"
      ],
      "metadata": {
        "id": "VwLMUPsAdB_6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a5UPIZGWQpSm"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Jmh-QcmAQpSm"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QXYleo7QpSm",
        "outputId": "b5b58976-142e-4453-af45-d10f87d28653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        " nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "qbqMxvQHQpSm",
        "outputId": "eabcaa89-cb2d-4c88-ab26-5a27e3694473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'scarf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "nltk.download('omw-1.4')\n",
        "lemmatizer.lemmatize(\"scarves\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-owJR78gQpSn"
      },
      "outputs": [],
      "source": [
        "string_for_lemmatizing = \"The friends of DeSoto love scarves.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hQTZcClWQpSn"
      },
      "outputs": [],
      "source": [
        "words = word_tokenize(string_for_lemmatizing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR_cH2HOQpSn",
        "outputId": "5d34beb3-6e8d-4806-a602-a110494791e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'friends', 'of', 'DeSoto', 'love', 'scarves', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OhjFFCHXQpSn"
      },
      "outputs": [],
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JleqXUy3QpSo",
        "outputId": "ef259635-36b9-4604-fa7f-3abb89abc37f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'friend', 'of', 'DeSoto', 'love', 'scarf', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "lemmatized_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "cMhslkCLQpSo",
        "outputId": "2ab0dec6-d7c7-41eb-b772-e561c76095f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"cats\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "fN5BiVb3QpSo",
        "outputId": "3c4a5815-05c9-4d71-bd61-9eb61aa18f51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQA_ZhjoQpSo"
      },
      "source": [
        "# Text Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I9xOilfQpSp"
      },
      "source": [
        "## N-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvTZVbPhQpSp"
      },
      "source": [
        "N-grams are the combination of multiple words used together. Ngrams with N=1 are called unigrams. Similarly, bigrams (N=2), trigrams (N=3) and so on can also be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ETsVty1AQpSp"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "C48eNyfkQpSp"
      },
      "outputs": [],
      "source": [
        "example_string = \"\"\"Muad'Dib learned rapidly because his first training was in how to learn.\n",
        "And the first lesson of all was the basic trust that he could learn.\n",
        "It's shocking to find how many people do not believe they can learn,\n",
        "and how many more believe learning to be difficult.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10S9QNBoQpSq",
        "outputId": "51617bca-941d-46de-fb30-c81b9f43eef6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList([\"Muad'Dib\", 'learned']),\n",
              " WordList(['learned', 'rapidly']),\n",
              " WordList(['rapidly', 'because']),\n",
              " WordList(['because', 'his']),\n",
              " WordList(['his', 'first']),\n",
              " WordList(['first', 'training']),\n",
              " WordList(['training', 'was']),\n",
              " WordList(['was', 'in']),\n",
              " WordList(['in', 'how']),\n",
              " WordList(['how', 'to']),\n",
              " WordList(['to', 'learn']),\n",
              " WordList(['learn', 'And']),\n",
              " WordList(['And', 'the']),\n",
              " WordList(['the', 'first']),\n",
              " WordList(['first', 'lesson']),\n",
              " WordList(['lesson', 'of']),\n",
              " WordList(['of', 'all']),\n",
              " WordList(['all', 'was']),\n",
              " WordList(['was', 'the']),\n",
              " WordList(['the', 'basic']),\n",
              " WordList(['basic', 'trust']),\n",
              " WordList(['trust', 'that']),\n",
              " WordList(['that', 'he']),\n",
              " WordList(['he', 'could']),\n",
              " WordList(['could', 'learn']),\n",
              " WordList(['learn', 'It']),\n",
              " WordList(['It', \"'s\"]),\n",
              " WordList([\"'s\", 'shocking']),\n",
              " WordList(['shocking', 'to']),\n",
              " WordList(['to', 'find']),\n",
              " WordList(['find', 'how']),\n",
              " WordList(['how', 'many']),\n",
              " WordList(['many', 'people']),\n",
              " WordList(['people', 'do']),\n",
              " WordList(['do', 'not']),\n",
              " WordList(['not', 'believe']),\n",
              " WordList(['believe', 'they']),\n",
              " WordList(['they', 'can']),\n",
              " WordList(['can', 'learn']),\n",
              " WordList(['learn', 'and']),\n",
              " WordList(['and', 'how']),\n",
              " WordList(['how', 'many']),\n",
              " WordList(['many', 'more']),\n",
              " WordList(['more', 'believe']),\n",
              " WordList(['believe', 'learning']),\n",
              " WordList(['learning', 'to']),\n",
              " WordList(['to', 'be']),\n",
              " WordList(['be', 'difficult'])]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "TextBlob(example_string).ngrams(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blkoSPXTQpSq"
      },
      "source": [
        "## Bag of Words(BOW) model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDb6csiGQpSq"
      },
      "source": [
        "Bag of Words (BoW) refers to the representation of text which describes the presence of words within the text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "6pB227f0QpSq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "uV_0SPUuQpSq"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjUpwR6PQpSr",
        "outputId": "1abb71cc-1ac0-486f-88f2-cdf4c9377e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   future  in  is  learn  love  months  nlp  they  two  will\n",
            "0       0   0   0      0     1       0    1     1    0     0\n",
            "1       1   0   1      0     0       0    1     0    0     0\n",
            "2       0   1   0      1     0       1    0     1    1     1\n"
          ]
        }
      ],
      "source": [
        "text = [\"They love NLP\",\n",
        "        \"NLP is future\",\n",
        "        \"They will learn in two months\"]\n",
        "vectorizer = CountVectorizer()\n",
        "count_matrix = vectorizer.fit_transform(text)\n",
        "count_array = count_matrix.toarray()\n",
        "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM4eOQLTQpSr",
        "outputId": "216d9f36-670e-42e4-b8f7-79d7754be5ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   future  in  is  learn  love  months  nlp  they  two  will\n",
            "0       0   1   0      1     1       1    1     1    1     0\n"
          ]
        }
      ],
      "source": [
        "text2 = ['They love NLP but can not learn in two months']\n",
        "count_array=vectorizer.transform(text2).toarray()\n",
        "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzTuUb6xQpSr",
        "outputId": "3a18ef79-0bee-412a-96bf-bd9b17424e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   am  am not  bad  feeling  feeling bad  food  food was  not  not bad  \\\n",
            "0   0       0    1        0            0     1         1    1        1   \n",
            "1   1       1    1        1            1     0         0    1        0   \n",
            "\n",
            "   not feeling  was  was not  \n",
            "0            0    1        1  \n",
            "1            1    0        0  \n"
          ]
        }
      ],
      "source": [
        "text = [\"food was not bad\",\"I am not feeling bad\"]\n",
        "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
        "count_matrix = vectorizer.fit_transform(text)\n",
        "count_array = count_matrix.toarray()\n",
        "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHXSiSx3QpSs"
      },
      "source": [
        "## Term Frequency – Inverse Document Frequency (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "wr4zM6rdQpSs"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfTqqA6OQpSs",
        "outputId": "f137476b-db01-4437-82cf-8e05cae229f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     future        is     learn      love       nlp       the      will\n",
            "0  0.000000  0.000000  0.000000  0.767495  0.453295  0.453295  0.000000\n",
            "1  0.608845  0.608845  0.000000  0.000000  0.359594  0.359594  0.000000\n",
            "2  0.000000  0.000000  0.608845  0.000000  0.359594  0.359594  0.608845\n"
          ]
        }
      ],
      "source": [
        "text = [\"i love the NLP\",\n",
        "        \"NLP is the future\",\n",
        "        \"i will learn the NLP\"]\n",
        "vectorizer = TfidfVectorizer()\n",
        "matrix = vectorizer.fit_transform(text)\n",
        "count_array = matrix.toarray()\n",
        "df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37G0UK4cQpSt"
      },
      "source": [
        "## Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm29MEd7QpSt"
      },
      "source": [
        "Word Embedding is the representation of text in the form of vectors. The underlying idea here is that similar words will have a minimum distance between their vectors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=[d.split() for d in text]"
      ],
      "metadata": {
        "id": "MMJq6doINaNW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZujy5UZOPXf",
        "outputId": "05329db2-4390-4f00-9332-2c5abee4103d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'love', 'the', 'NLP'],\n",
              " ['NLP', 'is', 'the', 'future'],\n",
              " ['i', 'will', 'learn', 'the', 'NLP']]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "USZBhD3IQpSt"
      },
      "outputs": [],
      "source": [
        "#convert text into the word2vec format.\n",
        "import gensim\n",
        "w2vecmodel=gensim.models.Word2Vec(sentences=X,vector_size=2,window=4,min_count=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7X5ZV3QpSu"
      },
      "source": [
        "Now, we can load the above word2vec file as a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuHBpap_QpSu",
        "outputId": "24aa334d-83ba-48d7-df1b-ee337bb507ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=8, vector_size=2, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "print(w2vecmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "2pbKY0v6QpSu",
        "outputId": "27a79ca0-6345-423e-bcac-89ee41d950c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'the', 'i', 'learn', 'will', 'future', 'is', 'love']\n"
          ]
        }
      ],
      "source": [
        "words = w2vecmodel.wv.index_to_key\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = w2vecmodel.wv.key_to_index\n",
        "print(words.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXBa49-rJM3h",
        "outputId": "a96137db-b974-44f4-e9f4-ea4f72c5ac06"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['NLP', 'the', 'i', 'learn', 'will', 'future', 'is', 'love'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "GXm4bkVQQpSu",
        "outputId": "a41a742d-6bb7-4918-ab70-432a0a35d28d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([0, 1, 2, 3, 4, 5, 6, 7])\n"
          ]
        }
      ],
      "source": [
        "print(words.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "pknB4PAUQpSv",
        "outputId": "f82eee9c-de41-4976-9ec3-204fbe22814e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.02681136  0.01182157]\n",
            " [ 0.25516748  0.45046365]\n",
            " [-0.4651475  -0.35584044]\n",
            " [ 0.32294363  0.4486494 ]\n",
            " [-0.2507714  -0.18816859]\n",
            " [ 0.36902523 -0.07667357]\n",
            " [-0.22683066  0.32770258]\n",
            " [-0.24300802 -0.09080088]]\n"
          ]
        }
      ],
      "source": [
        "print(w2vecmodel.wv.vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y = w2vecmodel.wv.vectors[:,0]\n",
        "x = w2vecmodel.wv.vectors[:,1]\n",
        "labels = words.keys()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x, y)\n",
        "\n",
        "for i, txt in enumerate(labels):\n",
        "    ax.annotate(txt, (x[i], y[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "ZH8Pb2TkP_Pw",
        "outputId": "7ae1f0a0-8107-40b0-b700-a478c47ef73f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}